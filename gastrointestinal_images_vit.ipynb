{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (0.0.post9)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pillow in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (10.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torchvision in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (0.15.2)\n",
            "Requirement already satisfied: numpy in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from torchvision) (1.26.0)\n",
            "Requirement already satisfied: requests in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.0.1 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from torchvision) (2.0.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from torchvision) (10.0.1)\n",
            "Requirement already satisfied: filelock in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (4.8.0)\n",
            "Requirement already satisfied: sympy in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from requests->torchvision) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: imbalanced-learn in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from imbalanced-learn) (1.26.0)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from imbalanced-learn) (1.11.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from imbalanced-learn) (1.3.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages (from imbalanced-learn) (3.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install sklearn\n",
        "%pip install pillow\n",
        "%pip install torchvision\n",
        "%pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k268imvu1VmC"
      },
      "source": [
        "**Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5w122GM21Y7D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1236 1740\n",
            "309 435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/hl/86tbqlkd413g631jyj246ld00000gn/T/ipykernel_74507/2894673893.py:21: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  print(len(train_annotations[HP] == True), len(train_annotations))\n",
            "/var/folders/hl/86tbqlkd413g631jyj246ld00000gn/T/ipykernel_74507/2894673893.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  print(len(val_annotations[HP] == True), len(val_annotations))\n"
          ]
        }
      ],
      "source": [
        "import PIL as Image\n",
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "#Preparing the dataset\n",
        "annotations = pd.read_csv(\"Datasets/annotations.csv\")\n",
        "HP = annotations.iloc[:,1] == \"HP\"\n",
        "SSA = annotations.iloc[:,1] == \"SSA\"\n",
        "annotations[\"HP\"] = HP\n",
        "annotations[\"SSA\"] = SSA\n",
        "t_annotations = annotations[annotations[\"Partition\"]==\"train\"]\n",
        "\n",
        "train_annotations, val_annotations = train_test_split(t_annotations, train_size=0.8, stratify=t_annotations[\"HP\"])\n",
        "\n",
        "# Just to confirm if the distribution is the same \n",
        "print(len(train_annotations[HP] == True), len(train_annotations))\n",
        "print(len(val_annotations[HP] == True), len(val_annotations))\n",
        "test_annotations = annotations[annotations[\"Partition\"]==\"test\"]\n",
        "root_dir = \"Datasets/images/\"\n",
        "\n",
        "class Plyops(Dataset):\n",
        "  def __init__(self, annotations, root_dir, transform = None) -> None:\n",
        "    self.annotations = annotations\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
        "    image = io.imread(img_path)\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    \n",
        "    y_label = torch.tensor([int(self.annotations.iloc[index, 4]),int(self.annotations.iloc[index, 5])])\n",
        "    return (image, y_label)\n",
        "  \n",
        "\n",
        "train_dataset = Plyops(train_annotations, root_dir)\n",
        "val_dataset = Plyops(val_annotations, root_dir)\n",
        "test_dataset = Plyops(test_annotations, root_dir)\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_dataloaders = {'train': DataLoader(train_dataset, batch_size=batch_size), 'val': DataLoader(val_dataset, batch_size=batch_size)}\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "dataset_sizes = {'train': len(train_dataloaders['train']), 'val': len(train_dataloaders['val']), 'test': len(test_dataloader)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz05uoxvzp5I"
      },
      "source": [
        "**Image** **Patching**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xKoPSFGA6VKm"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from  einops.einops import rearrange\n",
        "\n",
        "def transform_image(image, patch_size):\n",
        "  \"\"\"If H*W*C is the dimensions of the image, we should return N vectors of size\n",
        "  (P**2)*C, where P is the patch size and N = H*W/P i.e the number of patches\n",
        "  We use einops to rearrange\n",
        "\n",
        "  image: A four dimensional tensor\n",
        "\n",
        "  patch_size: int\n",
        "  \"\"\"\n",
        "  assert(image.shape[1]*image.shape[2]%patch_size == 0)\n",
        "  image = rearrange(image, 'b h w c -> b c h w')\n",
        "  return rearrange(image, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_size, p2 = patch_size)\n",
        "\n",
        "#Testing\n",
        "\n",
        "image = torch.rand(size=[1,9,9,1])\n",
        "image = transform_image(image, 3)\n",
        "assert(image.shape == torch.Size([1,9,9]))\n",
        "\n",
        "image = torch.rand(size=[1,9,9, 3])\n",
        "image = transform_image(image, 3)\n",
        "assert(image.shape == torch.Size([1, 9, 27]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyYu2J6vbVQ5"
      },
      "source": [
        "**Helper Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JbhPlLmJgL9",
        "outputId": "e3121507-feda-4061-b63f-d21cf6239fb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 5])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, dropout = 0.):\n",
        "    super(MLP, self).__init__()\n",
        "    self.l1 = nn.Linear(input_dim, hidden_dim)\n",
        "    self.act1 = nn.GELU()\n",
        "    self.drop1 = nn.Dropout(dropout)\n",
        "    self.l2 = nn.Linear(hidden_dim, input_dim)\n",
        "    self.drop2 = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.drop1(self.act1(self.l1(x)))\n",
        "    x = self.drop2(self.l2(x))\n",
        "    return x\n",
        "\n",
        "#simple test to see if dimensions match up\n",
        "mlp = MLP(5,6, 0.1)\n",
        "mlp(torch.ones(size=(1,5,5))).shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFmEpGs2fDz7"
      },
      "source": [
        "**Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_w5Jm_ORfIX4"
      },
      "outputs": [],
      "source": [
        "from einops import repeat\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "  \"\"\"This is the first part of the vision transformer\"\"\"\n",
        "  def __init__(self, num_channels, image_size, patch_size, embedding_dim):\n",
        "    super(PatchEmbedding, self).__init__()\n",
        "    #size parameters\n",
        "    self.patch_size = patch_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.image_size = image_size\n",
        "    num_patches = (image_size//patch_size)**2\n",
        "    #Need num channels for the below\n",
        "    self.proj = nn.Linear((patch_size**2)*num_channels, embedding_dim)\n",
        "    self.cls_token = nn.Parameter(torch.rand(1,1,embedding_dim))\n",
        "    #num patches is wrong\n",
        "    self.pos_embedding = nn.Parameter(torch.rand(1, num_patches + 1, embedding_dim))\n",
        "\n",
        "  def forward(self, img):\n",
        "    #transforms the image\n",
        "    img = transform_image(img, self.patch_size)\n",
        "    img = self.proj(img)\n",
        "    cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = img.shape[0])\n",
        "    img = torch.cat([cls_tokens, img], dim = 1)\n",
        "    img += self.pos_embedding\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq6vS600Jl25",
        "outputId": "d297da3a-c10a-4f68-da03-98379dded455"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 7, 3])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, embedding_dim, n_heads, hidden_dim, dropout=0):\n",
        "    super(TransformerEncoder, self).__init__()\n",
        "    #Required parameters\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.n_heads = n_heads\n",
        "\n",
        "    self.n1 = nn.LayerNorm(embedding_dim)\n",
        "    self.attention = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=n_heads, dropout=dropout)\n",
        "    self.n2 = nn.LayerNorm(embedding_dim)\n",
        "    self.mlp = MLP(embedding_dim, hidden_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = self.n1(x)\n",
        "    y = self.attention(z,z,z)[0] + x\n",
        "    x = self.mlp(self.n2(y)) + y\n",
        "    return x\n",
        "\n",
        "#simple test to see if dimensions add up\n",
        "te = TransformerEncoder(3,3,3)\n",
        "te(torch.ones(size = (1,7,3))).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUdCupzDgoKK",
        "outputId": "cb1dec8c-9cde-4bba-f6f8-1802d71a4fe9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class ViT(nn.Module):\n",
        "  def __init__(self, num_channels, image_size, patch_size, embedding_dim, n_heads, hidden_dim,n_layers, num_classes, dropout=0):\n",
        "    super(ViT, self).__init__()\n",
        "    self.patch_embedding = PatchEmbedding(num_channels, image_size, patch_size, embedding_dim)\n",
        "    self.transformer_encoder = TransformerEncoder(embedding_dim, n_heads, hidden_dim, dropout)\n",
        "    self.layer_norm = nn.LayerNorm(embedding_dim)\n",
        "    self.final_layer = nn.Linear(embedding_dim, num_classes)\n",
        "    self.n_layers = n_layers\n",
        "    self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.patch_embedding(x)\n",
        "    for _ in range(self.n_layers):\n",
        "      x = self.transformer_encoder(x)\n",
        "    y = self.layer_norm(x[:,0,:])\n",
        "    y = self.final_layer(y)\n",
        "    y = self.softmax(y)\n",
        "    return y\n",
        "\n",
        "#short test to see if dimensions checks out\n",
        "image = torch.ones(size = (3, 9,9, 1))\n",
        "vit = ViT(1, 9, 3, 4, 4, 7, 7, 2)\n",
        "vit(image).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUfVBxV61cBk"
      },
      "source": [
        "**Training and Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def visualize(*args, labels):\n",
        "  n = len(args[0])\n",
        "  x = np.arange(0,n, 1)\n",
        "  assert len(args) == len(labels), \"Each list must have a corresponding label\"\n",
        "  #Defining the functions used for plotting\n",
        "  for i in range(len(args)):\n",
        "    assert len(args[i]) == n, \"incorrect number of values\"\n",
        "    plt.plot(x, args[i], label = labels[i])\n",
        "  plt.xlim(0,n-1)\n",
        "  plt.xticks(range(0,n-1))\n",
        "  plt.ylim(0,1)\n",
        "  plt.title(\"Model Evaluation\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Metrics\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "def visualize_training(*args):\n",
        "  labels = [\"Precision\", \"Recall\", \"F1\", \"Specificity\"]\n",
        "  visualize(*args, labels= labels)\n",
        "\n",
        "def visualize_testing(c_matrix):\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import mean\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "def training_loop(dataloader, model, epochs, loss_function, optimizer, scheduler = None):\n",
        "  epoch_losses = []\n",
        "  epoch_precisions = []\n",
        "  epoch_recalls = []\n",
        "  epoch_f1_scores = []\n",
        "  epoch_specificities = []\n",
        "  for epoch in range(epochs):\n",
        "    print(\"Epoch: \" + str(epoch))\n",
        "    batch_tn = []\n",
        "    batch_fp = []\n",
        "    batch_tp = []\n",
        "    batch_fn = []\n",
        "    batch_losses = []\n",
        "    for x in ['train', 'val']:\n",
        "      if x == 'train':\n",
        "        model.train()\n",
        "      else:\n",
        "        model.eval()\n",
        "      for (data, label) in dataloader[x]:\n",
        "        data = data.to(torch.float32)\n",
        "        label = label.to(torch.float32)\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        output = model(data)\n",
        "        output.to(device)\n",
        "        loss = loss_function(output, label)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.no_grad():\n",
        "          predictions = torch.argmax(output.to('cpu'), 1)\n",
        "          label = torch.argmax(label.to('cpu'), 1)\n",
        "          tn, fp, fn, tp = confusion_matrix(label, predictions, labels=[0,1]).ravel()\n",
        "\n",
        "        if x == 'train':\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "        else:\n",
        "          batch_losses.append(loss.item())\n",
        "          batch_tn.append(tn)\n",
        "          batch_fp.append(fp)\n",
        "          batch_tp.append(tp)\n",
        "          batch_fn.append(fn)\n",
        "\n",
        "    epoch_loss = mean(batch_losses)\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    epoch_tn, epoch_fp, epoch_tp, epoch_fn = sum(batch_tn), sum(batch_fp), sum(batch_tp), sum(batch_fn)\n",
        "    \n",
        "    if scheduler:\n",
        "        scheduler.step(epoch_loss)\n",
        "\n",
        "    epoch_precision = epoch_tp/(epoch_tp + epoch_fp) if epoch_tp + epoch_fp != 0 else 0\n",
        "    epoch_precisions.append(epoch_precision)\n",
        "    epoch_recall = epoch_tp/(epoch_tp + epoch_fn) if epoch_tp + epoch_fp != 0 else 1\n",
        "    epoch_recalls.append(epoch_recall)\n",
        "    epoch_f1 = (2*epoch_recall*epoch_precision)/(epoch_recall + epoch_precision) if epoch_recall + epoch_precision != 0 else 0\n",
        "    epoch_f1_scores.append(epoch_f1)\n",
        "    epoch_specificity = epoch_tn/(epoch_tn + epoch_fp) if epoch_tn + epoch_fp != 0 else 1\n",
        "    epoch_specificities.append(epoch_specificity)\n",
        "          \n",
        "    print(\"Precision: \" + str(epoch_precision) \n",
        "          + \" F1: \" + str(epoch_f1))\n",
        "    print(\"Recall: \" + str(epoch_recall) + \" Specificity: \" + str(epoch_specificity))\n",
        "    print(\"Loss: \" + str(epoch_loss))\n",
        "\n",
        "  return [epoch_precisions, epoch_recalls, epoch_f1_scores, epoch_specificities]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Epoch 0 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6206, grad_fn=<DivBackward0>)\n",
            "Epoch: 1\n",
            "Epoch 1 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6098, grad_fn=<DivBackward0>)\n",
            "Epoch: 2\n",
            "Epoch 2 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6064, grad_fn=<DivBackward0>)\n",
            "Epoch: 3\n",
            "Epoch 3 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6050, grad_fn=<DivBackward0>)\n",
            "Epoch: 4\n",
            "Epoch 4 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6051, grad_fn=<DivBackward0>)\n",
            "Epoch: 5\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m#Small number of epochs since we dont have the computational resources\u001b[39;00m\n\u001b[1;32m     22\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n\u001b[0;32m---> 24\u001b[0m training_loop(train_dataloaders, model, epochs, loss_function, optimizer)\n",
            "Cell \u001b[0;32mIn[8], line 24\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(dataloader, model, epochs, loss_function, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     23\u001b[0m data, label \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), label\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 24\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     25\u001b[0m output\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     26\u001b[0m loss \u001b[39m=\u001b[39m loss_function(output, label)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch_embedding(x)\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers):\n\u001b[0;32m---> 14\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(x)\n\u001b[1;32m     15\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(x[:,\u001b[39m0\u001b[39m,:])\n\u001b[1;32m     16\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_layer(y)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     14\u001b[0m   z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn1(x)\n\u001b[0;32m---> 15\u001b[0m   y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(z,z,z)[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m x\n\u001b[1;32m     16\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn2(y)) \u001b[39m+\u001b[39m y\n\u001b[1;32m     17\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/modules/activation.py:1205\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1192\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1193\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1203\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1205\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1206\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1207\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1208\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1209\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1210\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1211\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m   1212\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1213\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1214\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[1;32m   1215\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[1;32m   1216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1217\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/functional.py:5333\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5330\u001b[0m B, Nt, E \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39mshape\n\u001b[1;32m   5331\u001b[0m q_scaled \u001b[39m=\u001b[39m q \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(E)\n\u001b[0;32m-> 5333\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_causal \u001b[39mand\u001b[39;00m attn_mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m), \u001b[39m\"\u001b[39m\u001b[39mFIXME: is_causal not implemented for need_weights\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5335\u001b[0m \u001b[39mif\u001b[39;00m attn_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5336\u001b[0m     attn_output_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbaddbmm(attn_mask, q_scaled, k\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "#We will vary embedding_dim, hidden_dim, n_heads, n_layers, later\n",
        "num_channels = 3\n",
        "image_size = 224\n",
        "patch_size = 16\n",
        "embedding_dim = 768\n",
        "hidden_dim = 3072\n",
        "n_heads = 12\n",
        "n_layers = 12\n",
        "num_classes = 2\n",
        "#large learning rate since not much time to train\n",
        "lr = 5e-4\n",
        "\n",
        "model = ViT(num_channels=num_channels, image_size=image_size, \n",
        "            patch_size=patch_size, embedding_dim=embedding_dim, \n",
        "            hidden_dim=hidden_dim, n_heads=n_heads, n_layers=n_layers, num_classes=num_classes)\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr = lr, weight_decay=1e-2, betas=(0.9,0.999))\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.1)\n",
        "#Small number of epochs since we dont have the computational resources\n",
        "epochs = 50\n",
        "\n",
        "args = training_loop(train_dataloaders, model, epochs, loss_function, optimizer)\n",
        "visualize_training(args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "from tabulate import tabulate\n",
        "\n",
        "def test(test_dataloader, model):\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  #Assumes that batch_size = len(test_dataloader)\n",
        "  for data, label in test_dataloader:\n",
        "    data = data.to(torch.float32)\n",
        "    label = label.to(torch.float32)\n",
        "    data, label = data.to(device), label.to(device)\n",
        "    output = model(data)\n",
        "    with torch.no_grad():\n",
        "      predictions = torch.argmax(output.to('cpu'), 1)\n",
        "      label = torch.argmax(label.to('cpu'), 1)\n",
        "      return confusion_matrix(label, predictions, labels=[0,1]), classification_report(label, predictions, output_dict=True)\n",
        "\n",
        "def visualize_testing(cm):\n",
        "  print(cm)\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, [0,1], rotation=45)\n",
        "  plt.yticks(tick_marks, [0,1])\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, format(cm[i, j], 'd'),\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/madhavgopakumar/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[617   0]\n",
            " [360   0]]\n",
            "╒═════════╤═════════════╤══════════╤════════════╤═══════════╕\n",
            "│ Label   │   Precision │   Recall │   F1-score │   Support │\n",
            "╞═════════╪═════════════╪══════════╪════════════╪═══════════╡\n",
            "│ HP      │    0.631525 │        1 │   0.774153 │       617 │\n",
            "├─────────┼─────────────┼──────────┼────────────┼───────────┤\n",
            "│ SSA     │    0        │        0 │   0        │       360 │\n",
            "╘═════════╧═════════════╧══════════╧════════════╧═══════════╛\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAHpCAYAAAC/c1fAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEyElEQVR4nO3deVxVdf7H8fe9KDsX3ABRRM1cKJfUUtJSkySz0nRSyyk0s5nSFim1ZnKv6Gelprm0mEvpWNbojGbmVlqJ5pKNqZFbYSlgmqAoi3B+fzjc6YYWVy98WV5PH+fx8J7zvd/zucyonz6f7/dcm2VZlgAAAAywmw4AAABUXiQiAADAGBIRAABgDIkIAAAwhkQEAAAYQyICAACMIREBAADGkIgAAABjSEQAAIAxJCKAh+3bt0/dunVTcHCwbDabli1b5tH5v//+e9lsNs2bN8+j85ZnnTt3VufOnU2HAeASkIigQjpw4ID+8pe/qGHDhvL19ZXD4VCHDh30yiuv6OzZsyV67/j4eO3atUvPPfec3n77bbVt27ZE71eaBg4cKJvNJofDccGf4759+2Sz2WSz2fTSSy+5Pf+RI0c0btw47dy50wPRAigPqpgOAPC0Dz/8UHfddZd8fHx033336eqrr1Zubq4+//xzjRgxQrt379brr79eIvc+e/askpKS9Pe//13Dhg0rkXtERUXp7Nmzqlq1aonM/0eqVKmiM2fOaPny5erbt6/LtYULF8rX11fZ2dmXNPeRI0c0fvx41a9fX61atSr2+1avXn1J9wNgHokIKpRDhw6pf//+ioqK0vr161W7dm3ntaFDh2r//v368MMPS+z+x44dkySFhISU2D1sNpt8fX1LbP4/4uPjow4dOugf//hHkURk0aJF6tGjhz744INSieXMmTPy9/eXt7d3qdwPgOfRmkGFMmnSJJ0+fVpz5sxxSUIKNWrUSI899pjz9blz5zRx4kRdccUV8vHxUf369fW3v/1NOTk5Lu+rX7++brvtNn3++ee67rrr5Ovrq4YNG2rBggXOMePGjVNUVJQkacSIEbLZbKpfv76k8y2Nwt//2rhx42Sz2VzOrVmzRh07dlRISIgCAwPVpEkT/e1vf3Nev9gakfXr1+uGG25QQECAQkJC1LNnT+3du/eC99u/f78GDhyokJAQBQcHa9CgQTpz5szFf7C/cc899+ijjz7SyZMnnee2bt2qffv26Z577iky/sSJE3ryySfVvHlzBQYGyuFwqHv37vr666+dYz799FNde+21kqRBgwY5WzyFn7Nz5866+uqrtX37dt14443y9/d3/lx+u0YkPj5evr6+RT5/XFycqlWrpiNHjhT7swIoWSQiqFCWL1+uhg0b6vrrry/W+AceeEBjxoxR69atNWXKFHXq1EmJiYnq379/kbH79+/Xn/70J9188816+eWXVa1aNQ0cOFC7d++WJPXu3VtTpkyRJN199916++23NXXqVLfi3717t2677Tbl5ORowoQJevnll3XHHXfoiy+++N33rV27VnFxcUpPT9e4ceOUkJCgTZs2qUOHDvr++++LjO/bt69OnTqlxMRE9e3bV/PmzdP48eOLHWfv3r1ls9n0z3/+03lu0aJFatq0qVq3bl1k/MGDB7Vs2TLddtttmjx5skaMGKFdu3apU6dOzqSgWbNmmjBhgiTpwQcf1Ntvv623335bN954o3Oe48ePq3v37mrVqpWmTp2qLl26XDC+V155RbVq1VJ8fLzy8/MlSa+99ppWr16t6dOnKyIiotifFUAJs4AKIiMjw5Jk9ezZs1jjd+7caUmyHnjgAZfzTz75pCXJWr9+vfNcVFSUJcnauHGj81x6errl4+NjPfHEE85zhw4dsiRZL774osuc8fHxVlRUVJEYxo4da/36j+GUKVMsSdaxY8cuGnfhPebOnes816pVKys0NNQ6fvy489zXX39t2e1267777ityv/vvv99lzjvvvNOqUaPGRe/5688REBBgWZZl/elPf7K6du1qWZZl5efnW+Hh4db48eMv+DPIzs628vPzi3wOHx8fa8KECc5zW7duLfLZCnXq1MmSZM2ePfuC1zp16uRy7uOPP7YkWc8++6x18OBBKzAw0OrVq9cffkYApYuKCCqMzMxMSVJQUFCxxq9cuVKSlJCQ4HL+iSeekKQia0mio6N1ww03OF/XqlVLTZo00cGDBy855t8qXFvyr3/9SwUFBcV6z9GjR7Vz504NHDhQ1atXd55v0aKFbr75Zufn/LW//vWvLq9vuOEGHT9+3PkzLI577rlHn376qVJTU7V+/XqlpqZesC0jnV9XYref/+smPz9fx48fd7adduzYUex7+vj4aNCgQcUa261bN/3lL3/RhAkT1Lt3b/n6+uq1114r9r0AlA4SEVQYDodDknTq1Klijf/hhx9kt9vVqFEjl/Ph4eEKCQnRDz/84HK+Xr16ReaoVq2afvnll0uMuKh+/fqpQ4cOeuCBBxQWFqb+/fvrvffe+92kpDDOJk2aFLnWrFkz/fzzz8rKynI5/9vPUq1aNUly67PceuutCgoK0rvvvquFCxfq2muvLfKzLFRQUKApU6boyiuvlI+Pj2rWrKlatWrpP//5jzIyMop9zzp16ri1MPWll15S9erVtXPnTk2bNk2hoaHFfi+A0kEiggrD4XAoIiJC33zzjVvv++1i0Yvx8vK64HnLsi75HoXrFwr5+flp48aNWrt2re6991795z//Ub9+/XTzzTcXGXs5LuezFPLx8VHv3r01f/58LV269KLVEEl6/vnnlZCQoBtvvFHvvPOOPv74Y61Zs0ZXXXVVsSs/0vmfjzu++uorpaenS5J27drl1nsBlA4SEVQot912mw4cOKCkpKQ/HBsVFaWCggLt27fP5XxaWppOnjzp3AHjCdWqVXPZYVLot1UXSbLb7eratasmT56sPXv26LnnntP69ev1ySefXHDuwjiTk5OLXPv2229Vs2ZNBQQEXN4HuIh77rlHX331lU6dOnXBBb6F3n//fXXp0kVz5sxR//791a1bN8XGxhb5mRQ3KSyOrKwsDRo0SNHR0XrwwQc1adIkbd261WPzA/AMEhFUKCNHjlRAQIAeeOABpaWlFbl+4MABvfLKK5LOtxYkFdnZMnnyZElSjx49PBbXFVdcoYyMDP3nP/9xnjt69KiWLl3qMu7EiRNF3lv4YK/fbikuVLt2bbVq1Urz5893+Yf9m2++0erVq52fsyR06dJFEydO1Kuvvqrw8PCLjvPy8ipSbVmyZIl++uknl3OFCdOFkjZ3jRo1SikpKZo/f74mT56s+vXrKz4+/qI/RwBm8EAzVChXXHGFFi1apH79+qlZs2YuT1bdtGmTlixZooEDB0qSWrZsqfj4eL3++us6efKkOnXqpC+//FLz589Xr169Lro19FL0799fo0aN0p133qlHH31UZ86c0axZs9S4cWOXxZoTJkzQxo0b1aNHD0VFRSk9PV0zZ85U3bp11bFjx4vO/+KLL6p79+6KiYnR4MGDdfbsWU2fPl3BwcEaN26cxz7Hb9ntdj3zzDN/OO62227ThAkTNGjQIF1//fXatWuXFi5cqIYNG7qMu+KKKxQSEqLZs2crKChIAQEBateunRo0aOBWXOvXr9fMmTM1duxY53biuXPnqnPnzho9erQmTZrk1nwASpDhXTtAifjuu++sIUOGWPXr17e8vb2toKAgq0OHDtb06dOt7Oxs57i8vDxr/PjxVoMGDayqVatakZGR1tNPP+0yxrLOb9/t0aNHkfv8dtvoxbbvWpZlrV692rr66qstb29vq0mTJtY777xTZPvuunXrrJ49e1oRERGWt7e3FRERYd19993Wd999V+Qev93iunbtWqtDhw6Wn5+f5XA4rNtvv93as2ePy5jC+/12e/DcuXMtSdahQ4cu+jO1LNftuxdzse27TzzxhFW7dm3Lz8/P6tChg5WUlHTBbbf/+te/rOjoaKtKlSoun7NTp07WVVdddcF7/nqezMxMKyoqymrdurWVl5fnMm748OGW3W63kpKSfvczACg9NstyY3UaAACAB7FGBAAAGEMiAgAAjCERAQAAxpCIAAAAY0hEAACAMSQiAADAmHL9QLOCggIdOXJEQUFBHn00NACgcrAsS6dOnVJERITzG6JLS3Z2tnJzcz06p7e3t3x9fT06Z0kr14nIkSNHFBkZaToMAEA5d/jwYdWtW7fU7pednS2/oBrSuTMenTc8PFyHDh0qV8lIuU5EgoKCJEne0fGyeRX/q8GByiTl05dMhwCUWacyM9WoQaTz35PSkpubK507I5+rBkme+vcrP1epu+cqNzeXRKS0FLZjbF7eJCLARTgcDtMhAGWesfa+B//9Kq+PSS/XiQgAAOWaTZKnkqByulSSRAQAAFNs9vOHp+Yqh8pn1AAAoEKgIgIAgCk2mwdbM+WzN0NFBACASuinn37Sn//8Z9WoUUN+fn5q3ry5tm3b5rxuWZbGjBmj2rVry8/PT7Gxsdq3b5/LHCdOnNCAAQPkcDgUEhKiwYMH6/Tp027FQSICAIAphWtEPHUU0y+//KIOHTqoatWq+uijj7Rnzx69/PLLqlatmnPMpEmTNG3aNM2ePVtbtmxRQECA4uLilJ2d7RwzYMAA7d69W2vWrNGKFSu0ceNGPfjgg279CGjNAABgiqHWzP/93/8pMjJSc+fOdZ5r0KCB8/eWZWnq1Kl65pln1LNnT0nSggULFBYWpmXLlql///7au3evVq1apa1bt6pt27aSpOnTp+vWW2/VSy+9pIiIiGLFQkUEAIAKJDMz0+XIyckpMubf//632rZtq7vuukuhoaG65ppr9MYbbzivHzp0SKmpqYqNjXWeCw4OVrt27ZSUlCRJSkpKUkhIiDMJkaTY2FjZ7XZt2bKl2PGSiAAAYIwn2zLn/0mPjIxUcHCw80hMTCxy14MHD2rWrFm68sor9fHHH+uhhx7So48+qvnz50uSUlNTJUlhYWEu7wsLC3NeS01NVWhoqMv1KlWqqHr16s4xxUFrBgAAU0qgNXP48GGXJyr7+PgUGVpQUKC2bdvq+eeflyRdc801+uabbzR79mzFx8d7Jp5ioiICAEAF4nA4XI4LJSK1a9dWdHS0y7lmzZopJSVF0vkvz5OktLQ0lzFpaWnOa+Hh4UpPT3e5fu7cOZ04ccI5pjhIRAAAMMXQrpkOHTooOTnZ5dx3332nqKgoSecXroaHh2vdunXO65mZmdqyZYtiYmIkSTExMTp58qS2b9/uHLN+/XoVFBSoXbt2xY6F1gwAAKYY2jUzfPhwXX/99Xr++efVt29fffnll3r99df1+uuv/3cqmx5//HE9++yzuvLKK9WgQQONHj1aERER6tWrl6TzFZRbbrlFQ4YM0ezZs5WXl6dhw4apf//+xd4xI5GIAABQ6Vx77bVaunSpnn76aU2YMEENGjTQ1KlTNWDAAOeYkSNHKisrSw8++KBOnjypjh07atWqVfL19XWOWbhwoYYNG6auXbvKbrerT58+mjZtmlux2CzLKq/fHKzMzEwFBwfLp/kQj32NMlDR/LL1VdMhAGVWZmamwmoEKyMjw2WBZ2ncNzg4WD7tRshWpegajkthnctRzpYXS/2zXC7WiAAAAGNozQAAYApfekciAgCAMW7udvnDucqh8hk1AACoEKiIAABgis3mwYoIrRkAAOAOu+384am5yiFaMwAAwBgqIgAAmMJiVRIRAACMYfsurRkAAGAOFREAAEyhNUNFBAAAmENFBAAAU1gjQiICAIAxtGZozQAAAHOoiAAAYAqtGRIRAACMoTVDawYAAJhDRQQAAFNozZCIAABgjgdbM+W0yVE+owYAABUCFREAAEyhNUNFBAAAmENFBAAAU2w2D27fLZ8VERIRAABM4TkitGYAAIA5VEQAADCFxaokIgAAGENrhtYMAAAwh4oIAACm0JohEQEAwBhaM7RmAACAOVREAAAwhdYMFREAAGAOFREAAAyx2WyyVfKKCIkIAACGkIjQmgEAAAZREQEAwBTbfw9PzVUOkYgAAGAIrRlaMwAAwCAqIgAAGEJFhEQEAABjSERozQAAAIOoiAAAYAgVESoiAADAICoiAACYwnNESEQAADCF1gytGQAAYBAVEQAADLHZ5MGKiGemKW0kIgAAGGKTB1sz5TQToTUDAACMoSICAIAhLFYlEQEAwBy279KaAQAA5pCIAABgyn9bM5443GnNjBs3rsj7mzZt6ryenZ2toUOHqkaNGgoMDFSfPn2UlpbmMkdKSop69Oghf39/hYaGasSIETp37pzbPwJaMwAAVEJXXXWV1q5d63xdpcr/UoLhw4frww8/1JIlSxQcHKxhw4apd+/e+uKLLyRJ+fn56tGjh8LDw7Vp0yYdPXpU9913n6pWrarnn3/erThIRAAAMMSTi1XdnadKlSoKDw8vcj4jI0Nz5szRokWLdNNNN0mS5s6dq2bNmmnz5s1q3769Vq9erT179mjt2rUKCwtTq1atNHHiRI0aNUrjxo2Tt7d3seOgNQMAgCGeasv8OqHJzMx0OXJyci5473379ikiIkINGzbUgAEDlJKSIknavn278vLyFBsb6xzbtGlT1atXT0lJSZKkpKQkNW/eXGFhYc4xcXFxyszM1O7du936GZCIAABQgURGRio4ONh5JCYmFhnTrl07zZs3T6tWrdKsWbN06NAh3XDDDTp16pRSU1Pl7e2tkJAQl/eEhYUpNTVVkpSamuqShBReL7zmDlozAACYUgLbdw8fPiyHw+E87ePjU2Ro9+7dnb9v0aKF2rVrp6ioKL333nvy8/PzUEDFQ0UEAABDSqI143A4XI4LJSK/FRISosaNG2v//v0KDw9Xbm6uTp486TImLS3NuaYkPDy8yC6awtcXWnfye0hEAACo5E6fPq0DBw6odu3aatOmjapWrap169Y5rycnJyslJUUxMTGSpJiYGO3atUvp6enOMWvWrJHD4VB0dLRb96Y1AwCAIaZ2zTz55JO6/fbbFRUVpSNHjmjs2LHy8vLS3XffreDgYA0ePFgJCQmqXr26HA6HHnnkEcXExKh9+/aSpG7duik6Olr33nuvJk2apNTUVD3zzDMaOnRosSowv0YiAgCAIaYSkR9//FF33323jh8/rlq1aqljx47avHmzatWqJUmaMmWK7Ha7+vTpo5ycHMXFxWnmzJnO93t5eWnFihV66KGHFBMTo4CAAMXHx2vChAlux00iAgBAJbN48eLfve7r66sZM2ZoxowZFx0TFRWllStXXnYsJCIAABhi8oFmZQWLVQEAgDFURAAAMKUEniNS3pCIAABgCK0ZWjMAAMAgKiIAABhCRYREBAAAY0hEaM0AAACDSETwhyJqBeutZ+/Tj5/8n04kTdbW9/6m1tH1nNd73tRSy2cO1Y+f/J/OfvWqWjSu4/L+erWr6+xXr17w6B17TWl/HMCY2TNnqEmj+goJ9NUN17fT1i+/NB0STLN5+CiHaM3gd4UE+Wn9vARt2LpPvYbN1LFfTqtRvVr6JfOMc4y/n7c27TygD9bs0KwxA4rM8WPaL6of+7TLufv7dNDw+2L18Re7S/wzAGXBkvfe1agRCZo+Y7auva6dXp02VXf0iNPXu5MVGhpqOjwYQmuGRAR/4IlBN+vH1F/0l3HvOM/9cOS4y5h/fLhV0vnKx4UUFFhKO37K5dwdXVrqgzU7lHU218MRA2XTtKmTNWjwEN03cJAkafrM2froow81f95bGjHyKcPRAebQmsHv6tGpuXbsSdHCSffrh3WJSvrHKA268/rLmvOaZpFq1TRS85cleShKoGzLzc3VVzu266ausc5zdrtdN90Uqy838+egMiusiHjqKI9IRPC7GtSpqSF33aD9Kcd0x8Mz9MaSz/XyyD9pwO3tLnnO+F4x2nvwqDZ/fciDkQJl188//6z8/HyFhoa5nA8NC1NqaqqhqICyoUwkIjNmzFD9+vXl6+urdu3a6UsWcJUZdrtNO789rLGvLtfXyT/qrX9+oblLN2nInzpe0ny+PlXVr3tbqiEAIMkmD1ZEyulqVeOJyLvvvquEhASNHTtWO3bsUMuWLRUXF6f09HTToUFS6s+Z2nvQ9b/Yvj2Uqsjwapc0352xreTv662FK0g2UXnUrFlTXl5eSk9Pczmfnpam8PBwQ1GhLKA1UwYSkcmTJ2vIkCEaNGiQoqOjNXv2bPn7++utt94yHRokJe08qMZRriv6r6wXqpSjJy5pvoG9rteHG3bp519OeyI8oFzw9vbWNa3b6JP165znCgoK9Mkn63Rd+xiDkQHmGU1EcnNztX37dsXGui7gio2NVVJS0dJ9Tk6OMjMzXQ6UrOnvrNd1zRtoxP3d1DCypvrd0lb39+mg197d6BxTzeGvFo3rqNkV5//LrnH9MLVoXEdhNYJc5moYWVMdW1+huUs3lepnAMqCRx9P0Nw5b+idBfP17d69enToQzqTlaX74geZDg0m8RwRs9t3CxdwhYW5LuAKCwvTt99+W2R8YmKixo8fX1rhQdL2PSnq98QbmvDIHfrbg931/U/HNeLFD7T4o23OMT06NdcbE+51vn77/+6XJD07e6Wee22l83x8zxj9lHZSa5OK/m8LVHR39e2nn48d04TxY5SWmqoWLVvpXytWFfn7D5ULzxGRbJZlWaZufuTIEdWpU0ebNm1STMz/ypMjR47Uhg0btGXLFpfxOTk5ysnJcb7OzMxUZGSkfJoPkc3Lu9TiBsqTX7a+ajoEoMzKzMxUWI1gZWRkyOFwlOp9g4ODFfXwEtl9/D0yZ0HOGf0w865S/yyXy2hFpHABV1qa6wKutIss4PLx8ZGPj09phQcAQImiImJ4jYi3t7fatGmjdetcF3CtW7fOpUICAEBFZLN59iiPjD/iPSEhQfHx8Wrbtq2uu+46TZ06VVlZWRo0iAVcAABUdMYTkX79+unYsWMaM2aMUlNT1apVK61axQIuAEDFd76S4anWjEemKXXGExFJGjZsmIYNG2Y6DAAASpcnWyrlNBEx/kAzAABQeZWJiggAAJURu2aoiAAAAIOoiAAAYIgnt92W04IIiQgAAKbY7TbZ7Z7JICwPzVPaaM0AAABjqIgAAGAIrRkSEQAAjGHXDK0ZAABgEBURAAAMoTVDIgIAgDG0ZmjNAAAAg6iIAABgCBURKiIAAMAgKiIAABjCYlUSEQAAjLHJg60Zlc9MhNYMAAAwhooIAACG0JohEQEAwBh2zdCaAQAABlERAQDAEFozJCIAABhDa4bWDAAAMIiKCAAAhtCaoSICAAAMoiICAIAhrBEhEQEAwBwPtmbK6RPeac0AAABzqIgAAGAIrRkSEQAAjGHXDK0ZAAAqvRdeeEE2m02PP/6481x2draGDh2qGjVqKDAwUH369FFaWprL+1JSUtSjRw/5+/srNDRUI0aM0Llz59y6N4kIAACGFLZmPHVciq1bt+q1115TixYtXM4PHz5cy5cv15IlS7RhwwYdOXJEvXv3dl7Pz89Xjx49lJubq02bNmn+/PmaN2+exowZ49b9SUQAADCksDXjqcNdp0+f1oABA/TGG2+oWrVqzvMZGRmaM2eOJk+erJtuuklt2rTR3LlztWnTJm3evFmStHr1au3Zs0fvvPOOWrVqpe7du2vixImaMWOGcnNzix0DiQgAABVIZmamy5GTk3PRsUOHDlWPHj0UGxvrcn779u3Ky8tzOd+0aVPVq1dPSUlJkqSkpCQ1b95cYWFhzjFxcXHKzMzU7t27ix0viQgAAIaURGsmMjJSwcHBziMxMfGC9168eLF27Nhxweupqany9vZWSEiIy/mwsDClpqY6x/w6CSm8XnituNg1AwBABXL48GE5HA7nax8fnwuOeeyxx7RmzRr5+vqWZnhFUBEBAMCQkqiIOBwOl+NCicj27duVnp6u1q1bq0qVKqpSpYo2bNigadOmqUqVKgoLC1Nubq5Onjzp8r60tDSFh4dLksLDw4vsoil8XTimOEhEAAAwxNRi1a5du2rXrl3auXOn82jbtq0GDBjg/H3VqlW1bt0653uSk5OVkpKimJgYSVJMTIx27dql9PR055g1a9bI4XAoOjq62LHQmgEAoJIJCgrS1Vdf7XIuICBANWrUcJ4fPHiwEhISVL16dTkcDj3yyCOKiYlR+/btJUndunVTdHS07r33Xk2aNEmpqal65plnNHTo0AtWYS6GRAQAAEPK8iPep0yZIrvdrj59+ignJ0dxcXGaOXOm87qXl5dWrFihhx56SDExMQoICFB8fLwmTJjg1n1IRAAAMKQsPeL9008/dXnt6+urGTNmaMaMGRd9T1RUlFauXHlZ92WNCAAAMIaKCAAAhpTl1kxpIREBAMAQmzzYmvHMNKWO1gwAADCGiggAAIbYbTbZPVQS8dQ8pY2KCAAAMIaKCAAAhpSl7bumkIgAAGAIu2ZozQAAAIOoiAAAYIjddv7w1FzlEYkIAACm2DzYUimniQitGQAAYAwVEQAADGHXDIkIAADG2P77y1NzlUe0ZgAAgDFURAAAMIRdM1REAACAQVREAAAwhCerkogAAGAMu2ZozQAAAIOoiAAAYIjdZpPdQ6UMT81T2oqViPz73/8u9oR33HHHJQcDAEBlQmummIlIr169ijWZzWZTfn7+5cQDAAAqkWIlIgUFBSUdBwAAlQ67Zi5zjUh2drZ8fX09FQsAAJUKrZlL2DWTn5+viRMnqk6dOgoMDNTBgwclSaNHj9acOXM8HiAAAKi43E5EnnvuOc2bN0+TJk2St7e38/zVV1+tN99806PBAQBQkRXumvHUUR65nYgsWLBAr7/+ugYMGCAvLy/n+ZYtW+rbb7/1aHAAAKBic3uNyE8//aRGjRoVOV9QUKC8vDyPBAUAQGVg++/hqbnKI7crItHR0frss8+KnH///fd1zTXXeCQoAAAqg8JdM546yiO3KyJjxoxRfHy8fvrpJxUUFOif//ynkpOTtWDBAq1YsaIkYgQAABWU2xWRnj17avny5Vq7dq0CAgI0ZswY7d27V8uXL9fNN99cEjECAFAh2W2ePcqjS3qOyA033KA1a9Z4OhYAACoVHmh2GQ8027Ztm/bu3Svp/LqRNm3aeCwoAABQObidiPz444+6++679cUXXygkJESSdPLkSV1//fVavHix6tat6+kYAQCosMppIcNj3F4j8sADDygvL0979+7ViRMndOLECe3du1cFBQV64IEHSiJGAAAqJHbNXEJFZMOGDdq0aZOaNGniPNekSRNNnz5dN9xwg0eDAwAAFZvbiUhkZOQFH1yWn5+viIgIjwQFAEBl4MndLuV114zbrZkXX3xRjzzyiLZt2+Y8t23bNj322GN66aWXPBocAACo2IpVEalWrZpL7ykrK0vt2rVTlSrn337u3DlVqVJF999/v3r16lUigQIAUNGwfbeYicjUqVNLOAwAACofvmummIlIfHx8SccBAAAqoUt+oJkkZWdnKzc31+Wcw+G4rIAAAKgs7Dab7B5qqXhqntLm9mLVrKwsDRs2TKGhoQoICFC1atVcDgAAUDw2m2eP8sjtRGTkyJFav369Zs2aJR8fH7355psaP368IiIitGDBgpKIEQAAVFBut2aWL1+uBQsWqHPnzho0aJBuuOEGNWrUSFFRUVq4cKEGDBhQEnECAFDhsGvmEioiJ06cUMOGDSWdXw9y4sQJSVLHjh21ceNGz0YHAEAFRmvmEhKRhg0b6tChQ5Kkpk2b6r333pN0vlJS+CV4AAAAxeF2a2bQoEH6+uuv1alTJz311FO6/fbb9eqrryovL0+TJ08uiRgBAKiQ2DVzCYnI8OHDnb+PjY3Vt99+q+3bt6tRo0Zq0aKFR4MDAAAV22U9R0SSoqKiFBUV5YlYAACoVDy5tqOcFkSKl4hMmzat2BM++uijlxwMAACVCbtmipmITJkypViT2Ww2EhEAAFBsxUpECnfJlFVdh9yjqn6BpsMAAMAtdl3C9tXfmas8Kq9xAwBQ7hW2Zjx1FNesWbPUokULORwOORwOxcTE6KOPPnJez87O1tChQ1WjRg0FBgaqT58+SktLc5kjJSVFPXr0kL+/v0JDQzVixAidO3fO7Z8BiQgAAJVM3bp19cILL2j79u3atm2bbrrpJvXs2VO7d++WdH6H7PLly7VkyRJt2LBBR44cUe/evZ3vz8/PV48ePZSbm6tNmzZp/vz5mjdvnsaMGeN2LJe9awYAAFwam02yG9g1c/vtt7u8fu655zRr1ixt3rxZdevW1Zw5c7Ro0SLddNNNkqS5c+eqWbNm2rx5s9q3b6/Vq1drz549Wrt2rcLCwtSqVStNnDhRo0aN0rhx4+Tt7V3sWKiIAABgiN3m2UOSMjMzXY6cnJzfjSE/P1+LFy9WVlaWYmJitH37duXl5Sk2NtY5pmnTpqpXr56SkpIkSUlJSWrevLnCwsKcY+Li4pSZmemsqhT7Z+DWaAAAUKZFRkYqODjYeSQmJl5w3K5duxQYGCgfHx/99a9/1dKlSxUdHa3U1FR5e3sX+dqWsLAwpaamSpJSU1NdkpDC64XX3HFJrZnPPvtMr732mg4cOKD3339fderU0dtvv60GDRqoY8eOlzIlAACVTkk8R+Tw4cNyOBzO8z4+Phcc36RJE+3cuVMZGRl6//33FR8frw0bNngkFne4XRH54IMPFBcXJz8/P3311VfOkk9GRoaef/55jwcIAACKr3AnTOFxsUTE29tbjRo1Ups2bZSYmKiWLVvqlVdeUXh4uHJzc3Xy5EmX8WlpaQoPD5ckhYeHF9lFU/i6cExxuZ2IPPvss5o9e7beeOMNVa1a1Xm+Q4cO2rFjh7vTAQBQaZXEGpFLVVBQoJycHLVp00ZVq1bVunXrnNeSk5OVkpKimJgYSVJMTIx27dql9PR055g1a9bI4XAoOjrarfu63ZpJTk7WjTfeWOR8cHBwkewJAABcnKnvmnn66afVvXt31atXT6dOndKiRYv06aef6uOPP1ZwcLAGDx6shIQEVa9eXQ6HQ4888ohiYmLUvn17SVK3bt0UHR2te++9V5MmTVJqaqqeeeYZDR069KIVmItxOxEJDw/X/v37Vb9+fZfzn3/+uRo2bOjudAAAoJSlp6frvvvu09GjRxUcHKwWLVro448/1s033yzp/Fe72O129enTRzk5OYqLi9PMmTOd7/fy8tKKFSv00EMPKSYmRgEBAYqPj9eECRPcjsXtRGTIkCF67LHH9NZbb8lms+nIkSNKSkrSk08+qdGjR7sdAAAAlZXdZpPdQyURd+aZM2fO71739fXVjBkzNGPGjIuOiYqK0sqVK4t9z4txOxF56qmnVFBQoK5du+rMmTO68cYb5ePjoyeffFKPPPLIZQcEAEBlwXfNXEIiYrPZ9Pe//10jRozQ/v37dfr0aUVHRyswkC+dAwAA7rnkR7x7e3u7vTIWAAD8j6nFqmWJ24lIly5dfvfhK+vXr7+sgAAAqCzs8uAaEZXPTMTtRKRVq1Yur/Py8rRz50598803io+P91RcAACgEnA7EZkyZcoFz48bN06nT5++7IAAAKgsaM14cJHtn//8Z7311luemg4AgAqvLD1Z1RSPJSJJSUny9fX11HQAAKAScLs107t3b5fXlmXp6NGj2rZtGw80AwDADTabew8i+6O5yiO3E5Hg4GCX13a7XU2aNNGECRPUrVs3jwUGAAAqPrcSkfz8fA0aNEjNmzdXtWrVSiomAAAqBRarurlGxMvLS926deNbdgEA8AAWq17CYtWrr75aBw8eLIlYAABAJeN2IvLss8/qySef1IoVK3T06FFlZma6HAAAoHhsHv5VHhV7jciECRP0xBNP6NZbb5Uk3XHHHS6PercsSzabTfn5+Z6PEgCACsiTLZXy2popdiIyfvx4/fWvf9Unn3xSkvEAAIBKpNiJiGVZkqROnTqVWDAAAFQmVETc3L77e9+6CwAA3GOz2Tz2b2t5/TfarUSkcePGf/hBT5w4cVkBAQCAysOtRGT8+PFFnqwKAAAuDa0ZNxOR/v37KzQ0tKRiAQAAlUyxE5Hy2nsCAKCs4hHvl7BrBgAAeIbdZvPYt+96ap7SVuxEpKCgoCTjAAAAlZBba0QAAIDnsFiVRAQAAHM8uEaknH7VjPtfegcAAOApVEQAADDELpvsHipleGqe0kYiAgCAIWzfpTUDAAAMoiICAIAh7JqhIgIAAAyiIgIAgCE8WZVEBAAAY1isSmsGAAAYREUEAABD7PJga4bniAAAAHfQmqE1AwAADKIiAgCAIXZ5riJQXisLJCIAABhis9lk81BPxVPzlLbymkABAIAKgIoIAACG2P57eGqu8oiKCAAAMIaKCAAAhvCIdxIRAACMKp/pg+fQmgEAAMZQEQEAwBCerEoiAgCAMTxHhNYMAAAwiIoIAACG8Ih3EhEAAIyhNVN+EygAAFABUBEBAMAQHvFORQQAABhEIgIAgCGFa0Q8dRRXYmKirr32WgUFBSk0NFS9evVScnKyy5js7GwNHTpUNWrUUGBgoPr06aO0tDSXMSkpKerRo4f8/f0VGhqqESNG6Ny5c279DEhEAAAwxO7ho7g2bNigoUOHavPmzVqzZo3y8vLUrVs3ZWVlOccMHz5cy5cv15IlS7RhwwYdOXJEvXv3dl7Pz89Xjx49lJubq02bNmn+/PmaN2+exowZ49bPgDUiAABUMqtWrXJ5PW/ePIWGhmr79u268cYblZGRoTlz5mjRokW66aabJElz585Vs2bNtHnzZrVv316rV6/Wnj17tHbtWoWFhalVq1aaOHGiRo0apXHjxsnb27tYsVARAQDAkJJozWRmZrocOTk5fxhHRkaGJKl69eqSpO3btysvL0+xsbHOMU2bNlW9evWUlJQkSUpKSlLz5s0VFhbmHBMXF6fMzEzt3r272D8DEhEAAAyxefiQpMjISAUHBzuPxMTE342hoKBAjz/+uDp06KCrr75akpSamipvb2+FhIS4jA0LC1NqaqpzzK+TkMLrhdeKi9YMAAAVyOHDh+VwOJyvfXx8fnf80KFD9c033+jzzz8v6dAuiEQEAABDSuLbdx0Oh0si8nuGDRumFStWaOPGjapbt67zfHh4uHJzc3Xy5EmXqkhaWprCw8OdY7788kuX+Qp31RSOKQ5aMwAAGGKXzaNHcVmWpWHDhmnp0qVav369GjRo4HK9TZs2qlq1qtatW+c8l5ycrJSUFMXExEiSYmJitGvXLqWnpzvHrFmzRg6HQ9HR0cWOhYoIAACVzNChQ7Vo0SL961//UlBQkHNNR3BwsPz8/BQcHKzBgwcrISFB1atXl8Ph0COPPKKYmBi1b99ektStWzdFR0fr3nvv1aRJk5SamqpnnnlGQ4cO/cN20K+RiAAAYEhJtGaKY9asWZKkzp07u5yfO3euBg4cKEmaMmWK7Ha7+vTpo5ycHMXFxWnmzJnOsV5eXlqxYoUeeughxcTEKCAgQPHx8ZowYYJbcZOIAABQyViW9YdjfH19NWPGDM2YMeOiY6KiorRy5crLioVEBAAAQ2z//eWpucojEhEAAAwx1ZopS9g1AwAAjKEiAgCAITY3t93+0VzlEYkIAACG0JqhNQMAAAyiIgIAgCFUREhEAAAwhu27tGYAAIBBVEQAADDEbjt/eGqu8oiKCAAAMIaKCAAAhrBGhEQEAABj2DVDawYAABhERQS/65ZmtXRLs1oKDfSRJKX8clbvfXVEO37MdI5pEhqgAW3rqHGtABVY0qHjZzR+1XfKzT//NdOBPl4aElNP19YLkWVZSvr+F72ZdFjZ5wqMfCbAlNkzZ2jK5BeVlpqq5i1aavLU6br2uutMhwWDbPJcS6WcFkRIRPD7jmfl6u0vf9KRzGzZJHVpXFNP39xICUv36PDJbDUJDdCYW67UBztT9camFOVblhpU91eB9b85hnduqOr+VTX2o+9UxW7TIzfW18MdozT500PGPhdQ2pa8965GjUjQ9Bmzde117fTqtKm6o0ecvt6drNDQUNPhwRB2zdCawR/YmpKh7T9m6Ghmjo5k5mjhtp+UnVegJqGBkqT720fqw93p+ud/UnX4ZLaOZOToi0O/6Nx/M5G6Ib5qExmsVz/7XvuOZWlv2mm9kZSijldUVzX/qiY/GlCqpk2drEGDh+i+gYPULDpa02fOlp+/v+bPe8t0aIBRJCIoNrtN6tiwmnyr2vVt+mkF+1ZRk9BAZZw9pxdub6p5A1rq2R5N1Cws0PmeJqEBOp1zTgd+PuM89/VPmbIsqXGtABMfAyh1ubm5+mrHdt3UNdZ5zm6366abYvXl5iSDkcE0m4d/lUe0ZvCHoqr56YU7msrby67svHy9sOaAfjyZ7Uwk+rWO0Lwth3XoxBl1aVRTE25trEc/2K2jmTmq5ldVGWfPucxXYEmncs5REUGl8fPPPys/P1+hoWEu50PDwpSc/K2hqFAWsGvGcEVk48aNuv322xURESGbzaZly5aZDAcX8VNGtoYv3aOR/9qrj/Ye06Od6qtuiK/z//Srvz2m9fuO69Dxs3pry2H9lJGtro1rmg0aAFAuGE1EsrKy1LJlS82YMcNkGPgD5wospWbm6MDxM3pn20/6/sRZ3X5VmH45kydJOnzyrMv4H09mq1agtyTpl7N5CvZzLbzZbVKQTxXn+4GKrmbNmvLy8lJ6eprL+fS0NIWHhxuKCmWBzcNHeWQ0EenevbueffZZ3XnnnSbDgJtsNqmql03pp3N1PCtXdYJ9Xa5HOHx17HSuJCk5PUuBPlV0RQ1/5/UWEQ7ZbNJ3x7JKNW7AFG9vb13Tuo0+Wb/Oea6goECffLJO17WPMRgZYF65WiOSk5OjnJwc5+vMzMzfGQ1P+HPbOtrxY4Z+Pp0rv6peuuGK6rq6dpDGr9onSVr2n1T1bxOhQ8fP6tCJM7rpyhqqE+KrSesOSDpfHdl+OEMP3xCl2V+kyMtu05Dr6+nzAyeoiKBSefTxBA25P15t2rRV22uv06vTpupMVpbuix9kOjQYZJdNdg8t7rCX05pIuUpEEhMTNX78eNNhVCohflX0eKcGquZfVVm5+frhxFmNX7VPX/90PglcvjtdVb3sGtw+UoE+Xvr+xFmN++g7pZ76X8I45dODejCmniZ0b6wCWUo6dFJvJqWY+kiAEXf17aefjx3ThPFjlJaaqhYtW+lfK1YpLCzsj9+MCsuTLZXymYZINsuyrD8eVvJsNpuWLl2qXr16XXTMhSoikZGRunXaJ6rqF3jR9wGV2eKBbU2HAJRZmZmZCqsRrIyMDDkcjlK9b3BwsNbu+EEBQZ65b9apTMW2jir1z3K5ylVFxMfHRz4+PqbDAADAMyiJlK9EBACAisSTDyLjgWaX4PTp09q/f7/z9aFDh7Rz505Vr15d9erVMxgZAAAoDUYTkW3btqlLly7O1wkJCZKk+Ph4zZs3z1BUAACUEg8+WbWcFkTMJiKdO3dWGVkrCwBAqWOJCF96BwAADGKxKgAAplASoSICAADMoSICAIAhbN8lEQEAwBibB3fNeGz3TSmjNQMAAIyhIgIAgCGsVSURAQDAHDIRWjMAAMAcKiIAABjCrhkSEQAAjGHXDK0ZAABgEBURAAAMYa0qFREAAGAQFREAAEyhJEIiAgCAKeyaoTUDAAAMoiICAIAhbN8lEQEAwBiWiNCaAQAABlERAQDAFEoiJCIAAJjCrhlaMwAAwCAqIgAAGMKuGSoiAAAYY/Pw4Y6NGzfq9ttvV0REhGw2m5YtW+Zy3bIsjRkzRrVr15afn59iY2O1b98+lzEnTpzQgAED5HA4FBISosGDB+v06dNuxUEiAgBAJZSVlaWWLVtqxowZF7w+adIkTZs2TbNnz9aWLVsUEBCguLg4ZWdnO8cMGDBAu3fv1po1a7RixQpt3LhRDz74oFtx0JoBAMAUg7tmunfvru7du1/wmmVZmjp1qp555hn17NlTkrRgwQKFhYVp2bJl6t+/v/bu3atVq1Zp69atatu2rSRp+vTpuvXWW/XSSy8pIiKiWHFQEQEAoALJzMx0OXJyctye49ChQ0pNTVVsbKzzXHBwsNq1a6ekpCRJUlJSkkJCQpxJiCTFxsbKbrdry5Ytxb4XiQgAAIbYPPxLkiIjIxUcHOw8EhMT3Y4rNTVVkhQWFuZyPiwszHktNTVVoaGhLterVKmi6tWrO8cUB60ZAAAMKYldM4cPH5bD4XCe9/Hx8cwNSggVEQAAKhCHw+FyXEoiEh4eLklKS0tzOZ+Wlua8Fh4ervT0dJfr586d04kTJ5xjioNEBAAAQ0xu3/09DRo0UHh4uNatW+c8l5mZqS1btigmJkaSFBMTo5MnT2r79u3OMevXr1dBQYHatWtX7HvRmgEAwBSDu2ZOnz6t/fv3O18fOnRIO3fuVPXq1VWvXj09/vjjevbZZ3XllVeqQYMGGj16tCIiItSrVy9JUrNmzXTLLbdoyJAhmj17tvLy8jRs2DD179+/2DtmJBIRAAAqpW3btqlLly7O1wkJCZKk+Ph4zZs3TyNHjlRWVpYefPBBnTx5Uh07dtSqVavk6+vrfM/ChQs1bNgwde3aVXa7XX369NG0adPcisNmWZblmY9U+jIzMxUcHKxbp32iqn6BpsMByqTFA9v+8SCgksrMzFRYjWBlZGS4LPAsjfsGBwdrx75UBQZ55r6nT2Wq9ZXhpf5ZLhcVEQAATPHgrply+uW7LFYFAADmUBEBAMAQg2tVywwqIgAAwBgqIgAAmEJJhEQEAABTfv0dMZ6YqzyiNQMAAIyhIgIAgCEl8aV35Q2JCAAAhrBEhNYMAAAwiIoIAACmUBIhEQEAwBR2zdCaAQAABlERAQDAEJs8uGvGM9OUOioiAADAGCoiAAAYwlpVEhEAAIzhgWa0ZgAAgEFURAAAMIbmDIkIAACG0JqhNQMAAAyiIgIAgCE0ZkhEAAAwhtYMrRkAAGAQFREAAAzhS++oiAAAAIOoiAAAYAqrVUlEAAAwhTyE1gwAADCIiggAAIawfZdEBAAAY9g1Q2sGAAAYREUEAABTWK1KIgIAgCnkIbRmAACAQVREAAAwhF0zVEQAAIBBVEQAADDGc9t3y+sqERIRAAAMoTVDawYAABhEIgIAAIyhNQMAgCG0ZqiIAAAAg6iIAABgCF96RyICAIAxtGZozQAAAIOoiAAAYAhfekdFBAAAGERFBAAAUyiJkIgAAGAKu2ZozQAAAIOoiAAAYAjbd0lEAAAwhiUitGYAAIBBVEQAADCFkggVEQAATLF5+Je7ZsyYofr168vX11ft2rXTl19+WQKf8veRiAAAUAm9++67SkhI0NixY7Vjxw61bNlScXFxSk9PL9U4SEQAADCkcNeMpw53TJ48WUOGDNGgQYMUHR2t2bNny9/fX2+99VbJfNiLKNdrRCzLkiTlnc0yHAlQdmVmZpoOASizTv33z0fhvyelzZN/Pgvn+u2cPj4+8vHxcTmXm5ur7du36+mnn3aes9vtio2NVVJSksdiKo5ynYicOnVKkrRm1G2GIwHKrrBHTUcAlH2nTp1ScHBwqd3P29tb4eHhurJBpEfnDQwMVGSk65xjx47VuHHjXM79/PPPys/PV1hYmMv5sLAwffvttx6N6Y+U60QkIiJChw8fVlBQkGzl9UkuFUxmZqYiIyN1+PBhORwO0+EAZQp/Psoey7J06tQpRURElOp9fX19dejQIeXm5np0Xsuyivx7+NtqSFlTrhMRu92uunXrmg4DF+BwOPiLFrgI/nyULaVZCfk1X19f+fr6Grl3zZo15eXlpbS0NJfzaWlpCg8PL9VYWKwKAEAl4+3trTZt2mjdunXOcwUFBVq3bp1iYmJKNZZyXREBAACXJiEhQfHx8Wrbtq2uu+46TZ06VVlZWRo0aFCpxkEiAo/y8fHR2LFjy3xPEjCBPx8oS/r166djx45pzJgxSk1NVatWrbRq1aoiC1hLms0ytWcJAABUeqwRAQAAxpCIAAAAY0hEAACAMSQiAADAGBIRAABgDIkILltBQYHy8/NNhwEAKIdIRHBZ9uzZo/vuu09xcXF66KGHtGnTJtMhAWUOiTpwcSQiuGTJycm6/vrrlZ+fr2uvvVZJSUl67LHHNG3aNNOhAWXGd999p6lTp+ro0aOmQwHKJJ6siktiWZYWLFiguLg4/eMf/5Ak/e1vf9O0adM0d+5cZWdna+TIkYajBMzav3+/YmJi9Msvv+j48eNKSEhQzZo1TYcFlCkkIrgkNptNR44cUWpqqvNcUFCQHn30Ufn6+mrx4sWqU6eOBgwYYDBKwJysrCwlJibqjjvu0LXXXqthw4bp3LlzGjlyJMkI8CskInCbZVmy2Wxq3bq19u3bp+TkZDVp0kTS+WTk/vvvV3JysmbOnKk777xT/v7+hiMGSp/dblebNm1Uo0YN9evXTzVr1lT//v0liWQE+BW+awaX7MCBA2rfvr3uuOMOvfLKKwoMDHQmKYcPH1ZUVJRWrlypW265xXSogBFZWVkKCAhwvn733Xd1991364knntBTTz2lGjVqqKCgQD/88IMaNGhgMFLAHCoiuGRXXHGF3nvvPXXv3l1+fn4aN26c87/yqlatqhYtWig4ONhwlIA5hUlIfn6+7Ha7+vXrJ8uydM8998hms+nxxx/XSy+9pB9++EFvv/021UNUSiQiuCxdunTRkiVLdNddd+no0aPq27evWrRooQULFig9PV2RkZGmQwSM8/LykmVZKigoUP/+/WWz2XTvvffq3//+tw4cOKCtW7eShKDSojUDj9ixY4cSEhL0/fffq0qVKvLy8tLixYt1zTXXmA4NKDMK/7q12Wzq2rWrdu7cqU8//VTNmzc3HBlgDokIPCYzM1MnTpzQqVOnVLt2bRbjAReQn5+vESNGaOrUqdq5c6datGhhOiTAKFoz8BiHwyGHw2E6DKDMu+qqq7Rjxw6SEEBURACg1BXuLgPAI94BoNSRhAD/QyICAACMIREBAADGkIgAAABjSEQAAIAxJCIAAMAYEhEAAGAMiQhg2MCBA9WrVy/n686dO+vxxx8v9Tg+/fRT2Ww2nTx58qJjbDabli1bVuw5x40bp1atWl1WXN9//71sNpt27tx5WfMAKJtIRIALGDhwoGw2m2w2m7y9vdWoUSNNmDBB586dK/F7//Of/9TEiROLNbY4yQMAlGU84h24iFtuuUVz585VTk6OVq5cqaFDh6pq1ap6+umni4zNzc2Vt7e3R+5bvXp1j8wDAOUBFRHgInx8fBQeHq6oqCg99NBDio2N1b///W9J/2unPPfcc4qIiFCTJk0kSYcPH1bfvn0VEhKi6tWrq2fPnvr++++dc+bn5yshIUEhISGqUaOGRo4cqd9+y8JvWzM5OTkaNWqUIiMj5ePjo0aNGmnOnDn6/vvv1aVLF0lStWrVZLPZNHDgQElSQUGBEhMT1aBBA/n5+ally5Z6//33Xe6zcuVKNW7cWH5+furSpYtLnMU1atQoNW7cWP7+/mrYsKFGjx6tvLy8IuNee+01RUZGyt/fX3379lVGRobL9TfffFPNmjWTr6+vmjZtqpkzZ7odC4DyiUQEKCY/Pz/l5uY6X69bt07Jyclas2aNVqxYoby8PMXFxSkoKEifffaZvvjiCwUGBuqWW25xvu/ll1/WvHnz9NZbb+nzzz/XiRMntHTp0t+973333ad//OMfmjZtmvbu3avXXntNgYGBioyM1AcffCBJSk5O1tGjR/XKK69IkhITE7VgwQLNnj1bu3fv1vDhw/XnP/9ZGzZskHQ+Yerdu7duv/127dy5Uw888ICeeuopt38mQUFBmjdvnvbs2aNXXnlFb7zxhqZMmeIyZv/+/Xrvvfe0fPlyrVq1Sl999ZUefvhh5/WFCxdqzJgxeu6557R37149//zzGj16tObPn+92PADKIQtAEfHx8VbPnj0ty7KsgoICa82aNZaPj4/15JNPOq+HhYVZOTk5zve8/fbbVpMmTayCggLnuZycHMvPz8/6+OOPLcuyrNq1a1uTJk1yXs/Ly7Pq1q3rvJdlWVanTp2sxx57zLIsy0pOTrYkWWvWrLlgnJ988oklyfrll1+c57Kzsy1/f39r06ZNLmMHDx5s3X333ZZlWdbTTz9tRUdHu1wfNWpUkbl+S5K1dOnSi15/8cUXrTZt2jhfjx071vLy8rJ+/PFH57mPPvrIstvt1tGjRy3LsqwrrrjCWrRokcs8EydOtGJiYizLsqxDhw5ZkqyvvvrqovcFUH6xRgS4iBUrVigwMFB5eXkqKCjQPffco3HjxjmvN2/e3GVdyNdff639+/crKCjIZZ7s7GwdOHBAGRkZOnr0qNq1a+e8VqVKFbVt27ZIe6bQzp075eXlpU6dOhU77v379+vMmTO6+eabXc7n5ubqmmuukSTt3bvXJQ5JiomJKfY9Cr377ruaNm2aDhw4oNOnT+vcuXNyOBwuY+rVq6c6deq43KegoEDJyckKCgrSgQMHNHjwYA0ZMsQ55ty5cwoODnY7HgDlD4kIcBFdunTRrFmz5O3trYiICFWp4vrHJSAgwOX16dOn1aZNGy1cuLDIXLVq1bqkGPz8/Nx+z+nTpyVJH374oUsCIJ1f9+IpSUlJGjBggMaPH6+4uDgFBwdr8eLFevnll92O9Y033iiSGHl5eXksVgBlF4kIcBEBAQFq1KhRsce3bt1a7777rkJDQ4tUBQrVrl1bW7Zs0Y033ijp/H/5b9++Xa1bt77g+ObNm6ugoEAbNmxQbGxskeuFFZn8/HznuejoaPn4+CglJeWilZRmzZo5F94W2rx58x9/yF/ZtGmToqKi9Pe//9157ocffigyLiUlRUeOHFFERITzPna7XU2aNFFYWJgiIiJ08OBBDRgwwK37A6gYWKwKeMiAAQNUs2ZN9ezZU5999pkOHTqkTz/9VI8++qh+/PFHSdJjjz2mF154QcuWLdO3336rhx9++HefAVK/fn3Fx8fr/vvv17Jly5xzvvfee5KkqKgo2Ww2rVixQseOHdPp06cVFBSkJ598UsOHD9f8+fN14MAB7dixQ9OnT3cuAP3rX/+qffv2acSIEUpOTtaiRYs0b948tz7vlVdeqZSUFC1evFgHDhzQtGnTLrjw1tfXV/Hx8fr666/12Wef6dFHH1Xfvn0VHh4uSRo/frwSExM1bdo0fffdd9q1a5fmzp2ryZMnuxUPgPKJRATwEH9/f23cuFH16tVT79691axZMw0ePFjZ2dnOCskTTzyhe++9V/Hx8YqJiVFQUJDuvPPO35131qxZ+tOf/qSHH35YTZs21ZAhQ5SVlSVJqlOnjsaPH6+nnnpKYWFhGjZsmCRp4sSJGj16tBITE9WsWTPdcsst+vDDD9WgQQNJ59dtfPDBB1q2bJlatmyp2bNn6/nnn3fr895xxx0aPny4hg0bplatWmnTpk0aPXp0kXGNGjVS7969deutt6pbt25q0aKFy/bcBx54QG+++abmzp2r5s2bq1OnTpo3b54zVgAVm8262Co5AACAEkZFBAAAGEMiAgAAjCERAQAAxpCIAAAAY0hEAACAMSQiAADAGBIRAABgDIkIAAAwhkQEAAAYQyICAACMIREBAADG/D/wIBWKIR3sbAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm, cr = test(test_dataloader, model)\n",
        "visualize_testing(cm)\n",
        "data = {\"Label\": [\"HP\", \"SSA\"], \"Precision\": [cr['0']['precision'], cr['1']['precision']], \"Recall\": [cr['0']['recall'], cr['1']['recall']],\n",
        "        \"F1-score\":[cr['0']['f1-score'], cr['1']['f1-score']], \"Support\": [cr['0']['support'], cr['1']['support']]}\n",
        "print(tabulate(data, headers=\"keys\", tablefmt=\"fancy_grid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Balancing the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3090 3090\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "#We are going to try Random oversampling with image augmentation first\n",
        "train_transforms2 = transforms.Compose([transforms.ToPILImage(), \n",
        "                                       transforms.Resize(size=(227, 227)), \n",
        "                                       transforms.RandomHorizontalFlip(), \n",
        "                                       transforms.RandomAdjustSharpness(sharpness_factor=0.8),\n",
        "                                       transforms.RandomGrayscale(),transforms.ToTensor()])\n",
        "\n",
        "#We are going to apply random transformation to each of the training examples, and see their effect on the model in addition\n",
        "#Note that t_annotations is only the training data not the testing\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "t_annotations_data, t_annotations_target = ros.fit_resample(t_annotations.drop([\"HP\"], axis=1), t_annotations['HP'])\n",
        "print(len(t_annotations_data[\"SSA\"] == True), len(t_annotations_data[\"SSA\"] == False))\n",
        "t_annotations_data[\"HP\"] = t_annotations_target\n",
        "train_annotations_ros, val_annotations_ros = train_test_split(t_annotations_data, train_size=0.8, stratify=t_annotations_data[\"HP\"])\n",
        "\n",
        "#Below is the training datasets with transformations applied\n",
        "train_dataset_ros = Plyops(train_annotations_ros, root_dir, train_transforms2)\n",
        "val_dataset_ros = Plyops(val_annotations_ros, root_dir, train_transforms2)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloaders_ros = {'train': DataLoader(train_dataset_ros, batch_size=batch_size), \n",
        "                                                    'val': DataLoader(val_dataset_ros, batch_size=batch_size)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Epoch 0 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6206, grad_fn=<DivBackward0>)\n",
            "Epoch: 1\n",
            "Epoch 1 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6098, grad_fn=<DivBackward0>)\n",
            "Epoch: 2\n",
            "Epoch 2 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6064, grad_fn=<DivBackward0>)\n",
            "Epoch: 3\n",
            "Epoch 3 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6050, grad_fn=<DivBackward0>)\n",
            "Epoch: 4\n",
            "Epoch 4 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6051, grad_fn=<DivBackward0>)\n",
            "Epoch: 5\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
            "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n",
            "\u001b[1;32m     21\u001b[0m \u001b[39m#Small number of epochs since we dont have the computational resources\u001b[39;00m\n",
            "\u001b[1;32m     22\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n",
            "\u001b[0;32m---> 24\u001b[0m training_loop(train_dataloaders, model, epochs, loss_function, optimizer)\n",
            "\n",
            "Cell \u001b[0;32mIn[8], line 24\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(dataloader, model, epochs, loss_function, optimizer)\u001b[0m\n",
            "\u001b[1;32m     22\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n",
            "\u001b[1;32m     23\u001b[0m data, label \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), label\u001b[39m.\u001b[39mto(device)\n",
            "\u001b[0;32m---> 24\u001b[0m output \u001b[39m=\u001b[39m model(data)\n",
            "\u001b[1;32m     25\u001b[0m output\u001b[39m.\u001b[39mto(device)\n",
            "\u001b[1;32m     26\u001b[0m loss \u001b[39m=\u001b[39m loss_function(output, label)\n",
            "\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
            "\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
            "\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n",
            "\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n",
            "\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
            "\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
            "\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\n",
            "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, x)\u001b[0m\n",
            "\u001b[1;32m     12\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch_embedding(x)\n",
            "\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers):\n",
            "\u001b[0;32m---> 14\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(x)\n",
            "\u001b[1;32m     15\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(x[:,\u001b[39m0\u001b[39m,:])\n",
            "\u001b[1;32m     16\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_layer(y)\n",
            "\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
            "\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
            "\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n",
            "\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n",
            "\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
            "\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
            "\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\n",
            "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n",
            "\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n",
            "\u001b[1;32m     14\u001b[0m   z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn1(x)\n",
            "\u001b[0;32m---> 15\u001b[0m   y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(z,z,z)[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m x\n",
            "\u001b[1;32m     16\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn2(y)) \u001b[39m+\u001b[39m y\n",
            "\u001b[1;32m     17\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n",
            "\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
            "\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
            "\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n",
            "\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n",
            "\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
            "\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
            "\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/modules/activation.py:1205\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n",
            "\u001b[1;32m   1191\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n",
            "\u001b[1;32m   1192\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n",
            "\u001b[1;32m   1193\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n",
            "\u001b[0;32m   (...)\u001b[0m\n",
            "\u001b[1;32m   1202\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n",
            "\u001b[1;32m   1203\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n",
            "\u001b[1;32m   1204\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "\u001b[0;32m-> 1205\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n",
            "\u001b[1;32m   1206\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n",
            "\u001b[1;32m   1207\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n",
            "\u001b[1;32m   1208\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n",
            "\u001b[1;32m   1209\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n",
            "\u001b[1;32m   1210\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n",
            "\u001b[1;32m   1211\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n",
            "\u001b[1;32m   1212\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n",
            "\u001b[1;32m   1213\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n",
            "\u001b[1;32m   1214\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n",
            "\u001b[1;32m   1215\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n",
            "\u001b[1;32m   1216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n",
            "\u001b[1;32m   1217\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
            "\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/functional.py:5333\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n",
            "\u001b[1;32m   5330\u001b[0m B, Nt, E \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39mshape\n",
            "\u001b[1;32m   5331\u001b[0m q_scaled \u001b[39m=\u001b[39m q \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(E)\n",
            "\u001b[0;32m-> 5333\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_causal \u001b[39mand\u001b[39;00m attn_mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m), \u001b[39m\"\u001b[39m\u001b[39mFIXME: is_causal not implemented for need_weights\u001b[39m\u001b[39m\"\u001b[39m\n",
            "\u001b[1;32m   5335\u001b[0m \u001b[39mif\u001b[39;00m attn_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;32m   5336\u001b[0m     attn_output_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbaddbmm(attn_mask, q_scaled, k\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
            "\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "#We will vary embedding_dim, hidden_dim, n_heads, n_layers, later\n",
        "num_channels = 3\n",
        "image_size = 224\n",
        "patch_size = 16\n",
        "embedding_dim = 768\n",
        "hidden_dim = 3072\n",
        "n_heads = 12\n",
        "n_layers = 12\n",
        "num_classes = 2\n",
        "#large learning rate since not much time to train\n",
        "lr = 5e-4\n",
        "\n",
        "model = ViT(num_channels=num_channels, image_size=image_size, \n",
        "            patch_size=patch_size, embedding_dim=embedding_dim, \n",
        "            hidden_dim=hidden_dim, n_heads=n_heads, n_layers=n_layers, num_classes=num_classes)\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr = lr, weight_decay=1e-2, betas=(0.9,0.999))\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.1)\n",
        "#Small number of epochs since we dont have the computational resources\n",
        "epochs = 50\n",
        "\n",
        "args = training_loop(train_dataloaders, model, epochs, loss_function, optimizer)\n",
        "visualize_training(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[340 277]\n",
            " [282  78]]\n",
            "╒═════════╤═════════════╤══════════╤════════════╤═══════════╕\n",
            "│ Label   │   Precision │   Recall │   F1-score │   Support │\n",
            "╞═════════╪═════════════╪══════════╪════════════╪═══════════╡\n",
            "│ HP      │    0.546624 │ 0.551053 │   0.54883  │       617 │\n",
            "├─────────┼─────────────┼──────────┼────────────┼───────────┤\n",
            "│ SSA     │    0.219718 │ 0.216667 │   0.218182 │       360 │\n",
            "╘═════════╧═════════════╧══════════╧════════════╧═══════════╛\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm, cr = test(test_dataloader, model)\n",
        "visualize_testing(cm)\n",
        "data = {\"Label\": [\"HP\", \"SSA\"], \"Precision\": [cr['0']['precision'], cr['1']['precision']], \"Recall\": [cr['0']['recall'], cr['1']['recall']],\n",
        "        \"F1-score\":[cr['0']['f1-score'], cr['1']['f1-score']], \"Support\": [cr['0']['support'], cr['1']['support']]}\n",
        "print(tabulate(data, headers=\"keys\", tablefmt=\"fancy_grid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Random Undersampling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1260 1260\n",
            "2472 1008\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "#Now lets try random undersampling \n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "t_annotations_data, t_annotations_target = rus.fit_resample(t_annotations.drop([\"HP\"], axis=1), t_annotations['HP'])\n",
        "print(len(t_annotations_data[\"SSA\"] == True), len(t_annotations_data[\"SSA\"] == False))\n",
        "t_annotations_data[\"HP\"] = t_annotations_target\n",
        "train_annotations_rus, val_annotations_rus = train_test_split(t_annotations_data, train_size=0.8, stratify=t_annotations_data[\"HP\"])\n",
        "\n",
        "#Below is the training datasets\n",
        "train_dataset_rus = Plyops(train_annotations_rus, root_dir, transform)\n",
        "val_dataset_rus = Plyops(val_annotations_rus, root_dir, transform)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloaders_rus = {'train': DataLoader(train_dataset_rus, batch_size=batch_size), \n",
        "                                                    'val': DataLoader(val_dataset_rus, batch_size=batch_size)}\n",
        "print(len(train_dataset_ros), len(train_dataset_rus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Epoch 0 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6206, grad_fn=<DivBackward0>)\n",
            "Epoch: 1\n",
            "Epoch 1 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6098, grad_fn=<DivBackward0>)\n",
            "Epoch: 2\n",
            "Epoch 2 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6064, grad_fn=<DivBackward0>)\n",
            "Epoch: 3\n",
            "Epoch 3 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6050, grad_fn=<DivBackward0>)\n",
            "Epoch: 4\n",
            "Epoch 4 average precision: 0.0 average f1: 0.0\n",
            "average recall: 0.0 average loss: tensor(0.6051, grad_fn=<DivBackward0>)\n",
            "Epoch: 5\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
            "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n",
            "\u001b[1;32m     21\u001b[0m \u001b[39m#Small number of epochs since we dont have the computational resources\u001b[39;00m\n",
            "\u001b[1;32m     22\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n",
            "\u001b[0;32m---> 24\u001b[0m training_loop(train_dataloaders, model, epochs, loss_function, optimizer)\n",
            "\n",
            "Cell \u001b[0;32mIn[8], line 24\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(dataloader, model, epochs, loss_function, optimizer)\u001b[0m\n",
            "\u001b[1;32m     22\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n",
            "\u001b[1;32m     23\u001b[0m data, label \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), label\u001b[39m.\u001b[39mto(device)\n",
            "\u001b[0;32m---> 24\u001b[0m output \u001b[39m=\u001b[39m model(data)\n",
            "\u001b[1;32m     25\u001b[0m output\u001b[39m.\u001b[39mto(device)\n",
            "\u001b[1;32m     26\u001b[0m loss \u001b[39m=\u001b[39m loss_function(output, label)\n",
            "\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
            "\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
            "\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n",
            "\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n",
            "\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
            "\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
            "\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\n",
            "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, x)\u001b[0m\n",
            "\u001b[1;32m     12\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch_embedding(x)\n",
            "\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers):\n",
            "\u001b[0;32m---> 14\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(x)\n",
            "\u001b[1;32m     15\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(x[:,\u001b[39m0\u001b[39m,:])\n",
            "\u001b[1;32m     16\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_layer(y)\n",
            "\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
            "\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
            "\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n",
            "\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n",
            "\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
            "\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
            "\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\n",
            "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n",
            "\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n",
            "\u001b[1;32m     14\u001b[0m   z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn1(x)\n",
            "\u001b[0;32m---> 15\u001b[0m   y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(z,z,z)[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m x\n",
            "\u001b[1;32m     16\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn2(y)) \u001b[39m+\u001b[39m y\n",
            "\u001b[1;32m     17\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n",
            "\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
            "\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
            "\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n",
            "\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n",
            "\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n",
            "\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
            "\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/modules/activation.py:1205\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n",
            "\u001b[1;32m   1191\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n",
            "\u001b[1;32m   1192\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n",
            "\u001b[1;32m   1193\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n",
            "\u001b[0;32m   (...)\u001b[0m\n",
            "\u001b[1;32m   1202\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n",
            "\u001b[1;32m   1203\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n",
            "\u001b[1;32m   1204\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "\u001b[0;32m-> 1205\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n",
            "\u001b[1;32m   1206\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n",
            "\u001b[1;32m   1207\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n",
            "\u001b[1;32m   1208\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n",
            "\u001b[1;32m   1209\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n",
            "\u001b[1;32m   1210\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n",
            "\u001b[1;32m   1211\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n",
            "\u001b[1;32m   1212\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n",
            "\u001b[1;32m   1213\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n",
            "\u001b[1;32m   1214\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n",
            "\u001b[1;32m   1215\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n",
            "\u001b[1;32m   1216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n",
            "\u001b[1;32m   1217\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
            "\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.7/envs/cv-project-env/lib/python3.10/site-packages/torch/nn/functional.py:5333\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n",
            "\u001b[1;32m   5330\u001b[0m B, Nt, E \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39mshape\n",
            "\u001b[1;32m   5331\u001b[0m q_scaled \u001b[39m=\u001b[39m q \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(E)\n",
            "\u001b[0;32m-> 5333\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_causal \u001b[39mand\u001b[39;00m attn_mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m), \u001b[39m\"\u001b[39m\u001b[39mFIXME: is_causal not implemented for need_weights\u001b[39m\u001b[39m\"\u001b[39m\n",
            "\u001b[1;32m   5335\u001b[0m \u001b[39mif\u001b[39;00m attn_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;32m   5336\u001b[0m     attn_output_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbaddbmm(attn_mask, q_scaled, k\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
            "\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "#We will vary embedding_dim, hidden_dim, n_heads, n_layers, later\n",
        "num_channels = 3\n",
        "image_size = 224\n",
        "patch_size = 16\n",
        "embedding_dim = 768\n",
        "hidden_dim = 3072\n",
        "n_heads = 12\n",
        "n_layers = 12\n",
        "num_classes = 2\n",
        "#large learning rate since not much time to train\n",
        "lr = 5e-4\n",
        "\n",
        "model = ViT(num_channels=num_channels, image_size=image_size, \n",
        "            patch_size=patch_size, embedding_dim=embedding_dim, \n",
        "            hidden_dim=hidden_dim, n_heads=n_heads, n_layers=n_layers, num_classes=num_classes)\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr = lr, weight_decay=1e-2, betas=(0.9,0.999))\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.1)\n",
        "#Small number of epochs since we dont have the computational resources\n",
        "epochs = 50\n",
        "\n",
        "args = training_loop(train_dataloaders, model, epochs, loss_function, optimizer)\n",
        "visualize_training(args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[340 277]\n",
            " [282  78]]\n",
            "╒═════════╤═════════════╤══════════╤════════════╤═══════════╕\n",
            "│ Label   │   Precision │   Recall │   F1-score │   Support │\n",
            "╞═════════╪═════════════╪══════════╪════════════╪═══════════╡\n",
            "│ HP      │    0.546624 │ 0.551053 │   0.54883  │       617 │\n",
            "├─────────┼─────────────┼──────────┼────────────┼───────────┤\n",
            "│ SSA     │    0.219718 │ 0.216667 │   0.218182 │       360 │\n",
            "╘═════════╧═════════════╧══════════╧════════════╧═══════════╛\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm, cr = test(test_dataloader, model)\n",
        "visualize_testing(cm)\n",
        "data = {\"Label\": [\"HP\", \"SSA\"], \"Precision\": [cr['0']['precision'], cr['1']['precision']], \"Recall\": [cr['0']['recall'], cr['1']['recall']],\n",
        "        \"F1-score\":[cr['0']['f1-score'], cr['1']['f1-score']], \"Support\": [cr['0']['support'], cr['1']['support']]}\n",
        "print(tabulate(data, headers=\"keys\", tablefmt=\"fancy_grid\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
